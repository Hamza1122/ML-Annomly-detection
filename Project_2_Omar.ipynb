{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Project_2_Omar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza1122/ML-Annomly-detection/blob/main/Project_2_Omar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ucvm7IH6da3"
      },
      "source": [
        "# **Project 2**, \n",
        "**Anomaly Detection Algorithm using Gaussian Mixture Model [20 Marks]**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGTYOwVXnmGv"
      },
      "source": [
        "Please fill out the following:\n",
        "\n",
        "\n",
        "*   Name: \n",
        "*   Student Number: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVh8MGvte8bX"
      },
      "source": [
        "##**Part 1: Getting started** [4 Marks]\n",
        "\n",
        "We are going to work with a credit card fraud dataset. This dataset contains 28 key features, which are not \n",
        "directly interpretable but contain meaningful information about the dataset.\n",
        "\n",
        "Load the dataset in CSV file using Pandas. The dataset is called `creditcard.csv`. Print out the first few columns of the dataset.\n",
        "\n",
        "* How many rows are there?\n",
        "\n",
        "  There are 284807 rows.\n",
        "* What features in the dataset are present aside from the 28 main features?\n",
        "\n",
        "  Besides 28 main features there are other feature like Time, Amount and Class  features.\n",
        "* Which column contains the targets?\n",
        "  \n",
        "  The column Class contains the targets values.\n",
        "\n",
        "* To what do the target values correspond?\n",
        "\n",
        "  The target values are [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9LfYqXUHbql",
        "outputId": "a7120805-f07a-4b2c-db92-fe612f31f982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=ee4c62a8d283f8c1d9fc1406289b570995304acf6cc825e8913f7020eb8da733\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg0gndnDe8bd",
        "outputId": "b43e7734-fc2a-4623-9a13-6432441f50a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import wget\n",
        "\n",
        "wget.download('https://github.com/aps1070-2019/datasets/raw/master/creditcard.tar.gz','creditcard.tar.gz')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'creditcard.tar.gz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h5z71s8e8bm",
        "outputId": "ead2ce97-3b9a-4e0b-d80e-39633d76ecdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!tar -zxvf creditcard.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creditcard.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bojUxOaHW5si"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "df = pd.read_csv('creditcard.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xR6EPYQZVoa",
        "outputId": "b191d40b-373e-428d-98eb-225a88ef7205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape[0] #rows size\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "284807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIVZ3GDOawcI",
        "outputId": "a78488a6-8ffe-40dd-b488-8723d728955c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "df.head(5) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjVFH_WuazjQ",
        "outputId": "7639c41e-c03b-41fb-8c85-74488d2b2ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "df['Class'].unique() #target column values"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w6cRXOee8b3"
      },
      "source": [
        "It's important when looking at a new dataset to figure out how many examples we have for each class.\n",
        "\n",
        "* What is the percentage of entries in the dataset for each class?\n",
        "  \n",
        "  Below is the code \"df.value_counts(normalize=True) * 100\". You can see the percentage results written over there.\n",
        "* Is this data considered balanced or unbalanced? Why is this the case?\n",
        "  \n",
        "  Yes, dataset is completely unabalanced. The reason is that there are 284315 values are \"0\" and 492 are \"1\" values.\n",
        "* Why is balance/imbalance important? How might this class ditribution affect a KNN classifier for example, which we explored in Project 1?\n",
        "\n",
        " The balanced class is very important because in the imbalanced classifications pose a challenge for predictive modeling as most of the machine learning algorithms used for classification were designed around the assumption of an equal number of examples for each class. This results in models that have poor predictive performance, specifically for the minority class. This is a problem because typically, the minority class is more important and therefore the problem is more sensitive to classification errors for the minority class than the majority class.\n",
        "  If the training set were to be imbalanced, and if the uniform distribution assumption were to still hold, the probability that the kNN of any random query point will belong to the class with more examples becomes higher\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2kHRnhzZUTk",
        "outputId": "32f08e38-f4b9-4568-d6f0-fac9f6a3493e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "### YOUR CODE HERE ###\n",
        "from numpy import loadtxt\n",
        "from numpy import unique\n",
        "\n",
        "df.value_counts(normalize=True) * 100"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      V1          V2          V3         V4         V5         V6         V7          V8          V9         V10        V11        V12        V13        V14        V15        V16        V17        V18        V19        V20        V21         V22        V23        V24        V25        V26        V27        V28        Amount  Class\n",
              "163152.0  -1.203617    1.574009    2.889277   3.381404   1.538663   3.698747   0.560211   -0.150911    0.124136   4.220998   1.384569  -0.706897  -0.256274  -1.562583   1.692915  -0.787338  -0.226776  -0.412354   0.234322   1.385597  -0.366727    0.522223  -0.357329  -0.870174  -0.134166   0.327019  -0.042648  -0.855262  1.51    0        0.006320\n",
              "          -1.196037    1.585949    2.883976   3.378471   1.511706   3.717077   0.585362   -0.156001    0.122648   4.217934   1.385525  -0.709405  -0.256168  -1.564352   1.693218  -0.785210  -0.228008  -0.412833   0.234834   1.375790  -0.370294    0.524395  -0.355170  -0.869790  -0.133198   0.327804  -0.035702  -0.858197  7.56    0        0.006320\n",
              "170731.0   2.033492    0.766969   -2.107555   3.631952   1.348594  -0.499907   0.945159   -0.286392   -1.370581   1.653073  -1.600434  -1.510901  -2.143280   1.189850  -0.875588   0.175808  -0.419433  -0.464717  -1.414528  -0.430560   0.241894    0.658545  -0.102644   0.580535   0.643637   0.347240  -0.116618  -0.078601  0.76    0        0.003160\n",
              "43153.0   -2.086016    2.203265    1.654339   2.941050  -1.683045   0.529728  -1.352162    1.793449   -0.723686   0.600365  -0.982212  -0.551636  -1.337000   0.834403   1.251862   0.033455   1.067978   0.160510   0.213087   0.079002   0.216444    0.567241  -0.035345   0.370201   0.157378   0.440341   0.210230   0.090558  0.76    0        0.003160\n",
              "68207.0   -13.192671   12.785971  -9.906650   3.320337  -4.801176   5.760059  -18.750889  -37.353443  -0.391540  -5.052502   4.406806  -4.610756  -1.909488  -9.072711  -0.226074  -6.211557  -6.248145  -3.149247   0.051576  -3.493050   27.202839  -8.887017   5.303607  -0.639435   0.263203  -0.108877   1.269566   0.939407  1.00    1        0.002107\n",
              "                                                                                                                                                                                                                                                                                                                                                      ...   \n",
              "128516.0  -0.718097    1.379483   -1.028163  -1.391419   1.733354  -1.424488   2.079085   -0.967967    0.464965   0.979399  -1.107038  -0.005980   0.705793  -0.166483  -0.100694  -0.741604  -0.946237  -0.385907   0.047764   0.474493   0.018806    0.853616  -0.391553  -0.583874  -0.090394   0.070217   0.227953   0.097015  7.70    0        0.000351\n",
              "          -1.605320   -0.099729   -0.761847  -0.217924   1.501036  -0.172438   0.248123    0.473783   -0.000272  -0.362453  -0.329404   0.536952   0.380144   0.656511   1.310089  -1.225375   0.504458  -1.265515  -0.993293  -0.515854   0.414621    1.806486   0.912984  -0.999173  -0.763147  -0.104569   0.274970   0.281219  0.99    0        0.000351\n",
              "128515.0   1.922330   -0.557369   -1.000299   0.025370   0.086882   0.560168  -0.513197    0.208442    1.077369  -0.007037  -0.145495   0.586234  -0.236570   0.235340   0.110858   0.726614  -1.166136   0.673512   0.655006  -0.066112  -0.222251   -0.720601   0.238414  -0.412577  -0.341709  -0.654596   0.006524  -0.036658  64.05   0        0.000351\n",
              "          -1.014617   -1.310073   -0.425960  -4.231576   1.181952  -2.528114   0.218553   -0.187614    0.190666  -0.946100   0.618314   0.723409  -0.785065   0.709114  -0.776556  -2.362777  -0.446026   1.684879  -0.846631  -0.302563   0.003295    0.335716   0.074028  -0.023902  -0.152366  -1.030824   0.417237   0.280758  21.68   0        0.000351\n",
              "0.0       -1.359807   -0.072781    2.536347   1.378155  -0.338321   0.462388   0.239599    0.098698    0.363787   0.090794  -0.551600  -0.617801  -0.991390  -0.311169   1.468177  -0.470401   0.207971   0.025791   0.403993   0.251412  -0.018307    0.277838  -0.110474   0.066928   0.128539  -0.189115   0.133558  -0.021053  149.62  0        0.000351\n",
              "Length: 283726, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4EPw3I-e8b7"
      },
      "source": [
        "Next, split the dataset into a training (70%) and testing set (30%). Set the random state to 0.\n",
        "\n",
        "Make sure to separate out the column corresponding to the targets.\n",
        "\n",
        "As mentioned earlier, in this lab we are going to use Gaussian distributions to model the data. To accomplish this, we are going to introduce `scipy`, a package which contains a wide variety of tools for working with scientific data in Python. Its `stats` package allows us to easily model various statistical distributions, and get information about them.\n",
        "\n",
        "Scipy's Gaussian distribution class is called `norm`. It takes two parameters - `loc`, which corresponds to the mean of your distribution, and `scale`, which corresponds to the standard deviation.\n",
        "\n",
        "* What are the mean and standard deviation for variable V20? Make sure to only use your training set for this calculation.\n",
        "\n",
        " The mean is 0.00043\n",
        " \n",
        " The std  is 0.770\n",
        "\n",
        "Use the code below to set up a Gaussian object for V20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZAbDaphe8bt",
        "outputId": "fddbc746-2ea3-4418-9442-dc3e4ba21434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "### Split the data  ###\n",
        "from sklearn.model_selection import train_test_split\n",
        "y=df['Class']\n",
        "X=df.drop(['Class'],axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "mean=X_train['V20'].mean()\n",
        "std=X_train['V20'].std()\n",
        "print(mean)\n",
        "print(std)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0004302219382028674\n",
            "0.7702574561360888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbvAZ42qe8b9"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "norm = stats.norm(\n",
        "\n",
        "    loc = mean,  ### REPLACE \"0\" WITH YOUR CODE TO GET THE MEAN OF V20 ### \n",
        "    scale =std  ### REPLACE \"0\" WITH YOUR CODE TO GET THE STANDARD DEVIATION OF V20 ### \n",
        "\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSFk1vjne8cG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns; sns.set(color_codes=True)\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "var_name = 'V20'\n",
        "\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "x = np.linspace(norm.ppf(0.01),\n",
        "                norm.ppf(0.99), 100)\n",
        "ax.plot(x, norm.pdf(x),\n",
        "       'r-', lw=5, alpha=0.6, label='norm pdf')\n",
        "ax.hist(X_train[var_name].values, density=True, histtype='stepfilled', bins=100);\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe41hNLJe8cQ"
      },
      "source": [
        "We can also look at the difference in distribution for some variables between fraudulent and non-fraudulent transactions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "YTGw4xNde8cV"
      },
      "source": [
        "features=[f for f in df.columns if 'V' in f]\n",
        "nplots=np.size(features)\n",
        "plt.figure(figsize=(15,4*nplots))\n",
        "gs = gridspec.GridSpec(nplots,1)\n",
        "for i, feat in enumerate(features):\n",
        "    ax = plt.subplot(gs[i])\n",
        "    sns.distplot(X_train[feat][y_train==1], bins=30)\n",
        "    sns.distplot(X_train[feat][y_train==0], bins=30)\n",
        "    ax.legend(['fraudulent', 'non-fraudulent'],loc='best')\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_title('Distribution of feature: ' + feat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCCCEVDHeC2P"
      },
      "source": [
        "Explain how these graphs could provide meaningful information about anomaly detection using a gaussian model. **[1]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eecAuMsDqQaC"
      },
      "source": [
        "## **Part 2: *Unsupervised,* One Gaussian** -- Single feature model with one Gaussian distribution: [3 Marks]\n",
        "We'll start by making a prediction using **a single feature of our dataset at a time**. \n",
        "\n",
        "  * Fit a Gaussian distribution on a feature of **the full training dataset** (this is unsupervised learning, we don't use the labels) using ``sklearn.mixture.GaussianMixture`` when ``n_components=1``. **[0.5]**\n",
        "  * Compute AUC (Area under the ROC Curve) based on ``sklearn.mixture.GaussianMixture.score_samples`` on the full training set (including both classes). **[0.5]**\n",
        "  * Repeat the above steps for each of the features and present your findings in a table. **[0.5]**\n",
        "  * Find the best feature to distinguish fraudulent transactions from non-fraudulent transactions based on AUC. **[0.5]**\n",
        "  *  To make a prediction based on a model's scores: If the ``score_samples`` is lower than a threshold, we consider that transaction as a fraud. Find an optimal threshold that maximizes the F1 Score in the training set. It's worth noting that for this last step, we're now using class labels for the first time, and so this method could be considered semi-supervised. **[1]**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vbf34-zsbMa"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViJHrg4AfICo"
      },
      "source": [
        "## **Part 3: *Supervised,* One Gaussian** -- Single feature model with one Gaussian distribution: [3 Marks]\n",
        "This part is similar to Part 2, but here we only fit a Gaussian distribution to the non-fraudulent transactions (and not all training data).\n",
        "\n",
        "  * Fit a Gaussian distribution on a feature of **non-fraudulent transactions** using ``sklearn.mixture.GaussianMixture`` when ``n_components=1``. **[0.5]**\n",
        "  * Compute AUC (Area under the ROC Curve) based on ``sklearn.mixture.GaussianMixture.score_samples`` on the full training set (including both classes). **[0.5]**\n",
        "  * Repeat the above steps for each of the features and present your findings in a table. **[0.5]**\n",
        "  * Find the best feature to distinguish fraudulent transactions from non-fraudulent transactions based on AUC. **[0.5]**\n",
        "  *  Find an optimal threshold that maximizes the F1 Score in the training set. **[0.5]**\n",
        "  *  Compare your results with Part 2 - does using a model based on the full dataset vs a model based only on non-fraudulent data make a big difference on performance? **[0.5]**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtcOHF9bnYY_"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEJUxd-6inbh"
      },
      "source": [
        "## **Part 4: *Supervised,* Two Gaussians** -- Single feature model with two Gaussian distributions. [3 Marks]\n",
        "Now we will use two separate distributions for fraudulent and non-fraudulent transactions.\n",
        "  *  Fit a Gaussian distribution ($G_1$) on a feature of non-fraudulent transactions using ``sklearn.mixture.GaussianMixture`` when ``n_components=1``. Use the feature that lead to the best AUC in Part 3. **[0.5]**\n",
        "  * Fit another Gaussian distribution ($G_2$) on the same feature but for fraudulent transactions using ``sklearn.mixture.GaussianMixture`` when ``n_components=1``. **[0.5]**\n",
        "  * Compute the score samples ($S$) for both $G_1$ and $G_2$ on the whole training set to get $S_1$ and $S_2$, respectively. **[0.5]**\n",
        "  * Find an optimal $c$ (a real number) that maximizes F1 Score for a model such that if $S_1 < c \\times S_2$, the transaction is classified as a fraud. For example, if $c=1$ we could say that if $S_2$ is greater than $S_1$ then the transaction is a fraud (the transaction belongs to the $G_2$ distribution which represents fraudulent transactions). **[0.5]**\n",
        "  * Repeat the steps above for at least two other features. **[1]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJpFiTj5jaAD"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac1nyvCPe8ce"
      },
      "source": [
        "## **Part 5: Multivariate and Mixture of Gaussians Distribution** [6 Marks]\n",
        "We now want to build an outlier detection model that performs well in terms of F1 score. To design your model, you can benefit from:\n",
        "\n",
        "*   No restrictions on the number of features - use as few or as many as you want! (multivariate). \n",
        "*   To fit your model, you can take advantage of the Gaussian mixture model where you can set the number of components [help](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html) (take a look at the hint below).\n",
        "*   You can choose to fit your Gaussians on non-fraudulent transactions or to both classes. **Make sure you have at least one model of each group**.\n",
        "* You can use supervised and/or unsupervised methods. **Make sure you have at least one model of each group**.\n",
        "\n",
        "It is up to you how to design your model. Try at least 12 different models and report the AUC and best F1 score for each one. What kind of model works better? How many features are best (and which ones)? How many Gaussians? How many components? Summarize your findings with tables and plots. **[6]**\n",
        "\n",
        "**HINT!**\n",
        "\n",
        "Does it make sense to have more than two Gaussians (or a mixture with more than 2 components) in this kind of (binary) task?\n",
        "\n",
        " The answer is YES, and it depends on the distribution of data. Remember the tutorial, where we had 5 clusters and fit a mixture of 5 Gaussians to detect outliers. Consider the transaction is valid if it is close to each one of those five clusters, and it is not valid if it is not close to them! For example (figure below), assume we have a high volume of legitimate transactions in the morning until lunchtime (9 AM to 12 PM). We have fewer transactions during lunchtime. Then we have another pick between (1 PM to 4 PM). In this example, it is reasonable to have two valid clusters (compenents), one for the morning and another for the afternoon transactions.\n",
        " ![Example:](https://raw.githubusercontent.com/aps1070-2019/datasets/master/img/AMoW2.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN1H_N-TJZ0H"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NzRkO9sIwKS"
      },
      "source": [
        "## **Part 6: Evaluating performance on test set:** [1 Mark]\n",
        "**Which model worked better?** Pick your best model among all models and apply it to your test set. Report the F1 Score, precision and recall on the test set. **[1]**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yClYMXloe8cg"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}